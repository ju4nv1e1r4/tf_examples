{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 09:34:23.951239: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-12 09:34:24.034515: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-12 09:34:24.119868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741782864.217870    8384 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741782864.242116    8384 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 09:34:24.417290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tensor da Tensorflow:\n",
      " tf.Tensor(\n",
      "[[2 4 4]\n",
      " [5 9 8]\n",
      " [2 3 4]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor_tf = tf.random.uniform( # aqui criamos um tensor com essas caracteristicas, aleatoriamente e uniforme\n",
    "    shape=(3,3), # formato é 3x3\n",
    "    minval=0,    # valor minimo\n",
    "    maxval=10,   # valor máximo\n",
    "    dtype=tf.int32 # tipagem: i32\n",
    ")\n",
    "\n",
    "print(\"=> Tensor da Tensorflow:\\n\", tensor_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tensor da tensorflow transposto:\n",
      " tf.Tensor(\n",
      "[[2 5 2]\n",
      " [4 9 3]\n",
      " [4 8 4]], shape=(3, 3), dtype=int32)\n",
      "\n",
      "=> Soma por linha:\n",
      " tf.Tensor([10 22  9], shape=(3,), dtype=int32)\n",
      "\n",
      "=> Soma por coluna:\n",
      " tf.Tensor([ 9 16 16], shape=(3,), dtype=int32)\n",
      "\n",
      "=> Tensor com diemnsão expandida:\n",
      " tf.Tensor(\n",
      "[[[2 4 4]\n",
      "  [5 9 8]\n",
      "  [2 3 4]]], shape=(1, 3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# manipularemos este tensor\n",
    "tensor_transposto = tf.transpose(tensor_tf)                    # aqui vamos transpor este tensor\n",
    "print(\"=> Tensor da tensorflow transposto:\\n\", tensor_transposto) \n",
    "\n",
    "tensor_soma_por_linhas = tf.reduce_sum(tensor_tf, axis=1)      # intuitivamente, somando por linhas\n",
    "tensor_soma_por_colunas = tf.reduce_sum(tensor_tf, axis=0)     # intuitivamente, somando por colunas\n",
    "print(\"\\n=> Soma por linha:\\n\", tensor_soma_por_linhas)\n",
    "print(\"\\n=> Soma por coluna:\\n\", tensor_soma_por_colunas)\n",
    "\n",
    "tensor_expandido = tf.expand_dims(tensor_tf, axis=0)\n",
    "print(\"\\n=> Tensor com diemnsão expandida:\\n\", tensor_expandido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tensor da Tensorflow convertido para NumPy:\n",
      " [[2 4 4]\n",
      " [5 9 8]\n",
      " [2 3 4]]\n",
      "\n",
      "=> Média por linha:\n",
      " [3.33333333 7.33333333 3.        ]\n",
      "\n",
      "=> Desvio padrão total:\n",
      " 2.3147407395555177\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tensor_np = tensor_tf.numpy()         # convertemos para numpy\n",
    "print(\"=> Tensor da Tensorflow convertido para NumPy:\\n\", tensor_np)\n",
    "\n",
    "np_mean = np.mean(tensor_np, axis=1)  # média por linha\n",
    "np_std = np.std(tensor_np)            # desvio padrão\n",
    "\n",
    "\n",
    "print(\"\\n=> Média por linha:\\n\", np_mean)\n",
    "print(\"\\n=> Desvio padrão total:\\n\", np_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tensor da PyTorch:\n",
      " tensor([[9, 5, 1],\n",
      "        [6, 3, 7],\n",
      "        [4, 5, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_torch = torch.randint(0, 10, (3, 3))\n",
    "print(\"=> Tensor da PyTorch:\\n\", tensor_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tensor da PyTorch transposto:\n",
      " tensor([[9, 6, 4],\n",
      "        [5, 3, 5],\n",
      "        [1, 7, 0]])\n",
      "\n",
      "=> Soma por linha (PyTorch):\n",
      " tensor([15, 16,  9])\n",
      "\n",
      "=> Soma por coluna (PyTorch):\n",
      " tensor([19, 13,  8])\n",
      "\n",
      "=> Tensor com dimensão extra (PyTorch):\n",
      " tensor([[[9, 5, 1],\n",
      "         [6, 3, 7],\n",
      "         [4, 5, 0]]])\n"
     ]
    }
   ],
   "source": [
    "# manipulações equivalentes com o pytorch\n",
    "tensor_torch_transposto = torch.transpose(tensor_torch, 0, 1)\n",
    "print(\"=> Tensor da PyTorch transposto:\\n\", tensor_torch_transposto)\n",
    "\n",
    "tensor_pt_soma_por_linha = torch.sum(tensor_torch, dim=1)\n",
    "tensor_pt_soma_por_coluna = torch.sum(tensor_torch, dim=0)\n",
    "print(\"\\n=> Soma por linha (PyTorch):\\n\", tensor_pt_soma_por_linha)\n",
    "print(\"\\n=> Soma por coluna (PyTorch):\\n\", tensor_pt_soma_por_coluna)\n",
    "\n",
    "tensor_torch_expandido = tensor_torch.unsqueeze(0)\n",
    "print(\"\\n=> Tensor com dimensão extra (PyTorch):\\n\", tensor_torch_expandido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tensor da PyTorch convertivo para tensor da tensorflow:\n",
      " tf.Tensor(\n",
      "[[9 5 1]\n",
      " [6 3 7]\n",
      " [4 5 0]], shape=(3, 3), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tensor_tf_from_torch = tf.convert_to_tensor(tensor_torch)\n",
    "\n",
    "print(\"=> Tensor da PyTorch convertivo para tensor da tensorflow:\\n\", tensor_tf_from_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Tensor da PyTorch criado a partir do TensorFlow:\n",
      " tensor([[2, 4, 4],\n",
      "        [5, 9, 8],\n",
      "        [2, 3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "tensor_torch_from_tf = torch.tensor(tensor_tf.numpy())\n",
    "print(\"\\n=> Tensor da PyTorch criado a partir do TensorFlow:\\n\", tensor_torch_from_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Tensor da tensorflow criado a partir do PyTorch:\n",
      " tf.Tensor(\n",
      "[[9 5 1]\n",
      " [6 3 7]\n",
      " [4 5 0]], shape=(3, 3), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tensor_tf_from_torch = tf.convert_to_tensor(tensor_torch.numpy())\n",
    "print(\"\\n=> Tensor da tensorflow criado a partir do PyTorch:\\n\", tensor_tf_from_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 10:13:07.503712: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 800000000 exceeds 10% of free system memory.\n",
      "2025-03-12 10:13:07.887239: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 800000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Forçando a barra da tensorflow... (ou quase isso)\n",
    "big_tensor = tf.random.uniform(\n",
    "    shape=(500_000, 200), # 500.000 * 200 = 100.000.000\n",
    "    minval=0,\n",
    "    maxval=599.1,\n",
    "    dtype=tf.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de tudo, vou registrar a análise desse warning:\n",
    "\n",
    "O erro vem do alocador de memória da CPU do TensorFlow, indicando que a tentativa de alocar 800 MB (800000000 bytes) de memória ultrapassou 10% da memória RAM disponível.\n",
    "\n",
    "- Se este computador tem 16 GB de RAM total, provavelmente o sistema estava com ~8 GB livres.\n",
    "- 10% disso seria ~800 MB, exatamente o que o TensorFlow tentou alocar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contornando a situação\n",
    "big_tensor = tf.random.uniform(\n",
    "    shape=(500_000, 200), # 500.000 * 200 = os mesmos 100.000.000\n",
    "    minval=0,\n",
    "    maxval=599.1,\n",
    "    dtype=tf.float32 # usando um tipo de float menor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não tem warning mais..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo registrado da execução da operação: 0.9016454219818115 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "A = tf.random.uniform((100_000, 2000), dtype=tf.float32)\n",
    "B = tf.random.uniform((2000, 1000), dtype=tf.float32)\n",
    "\n",
    "# calcular o tempo de execução\n",
    "start = time.time()\n",
    "C = tf.matmul(A, B)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tempo registrado da execução da operação:\", end - start, \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo registrado da execução da operação: 0.37029480934143066 segundos\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "exp_tensor = tf.exp(big_tensor)  # exponencial\n",
    "sin_tensor = tf.sin(big_tensor)  # seno\n",
    "sqrt_tensor = tf.sqrt(big_tensor)  # raiz quadrada\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Tempo registrado da execução da operação:\", end_time - start_time, \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tamanho original: (500000, 200)\n",
      "=> Tamanho esparso: tf.Tensor([500000    200], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# tensor esparso\n",
    "tensor_esparso = tf.sparse.from_dense(big_tensor)\n",
    "\n",
    "print(\"=> Tamanho original:\", big_tensor.shape)\n",
    "print(\"=> Tamanho esparso:\", tensor_esparso.dense_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Tensor Esparso:\n",
      " SparseTensor(indices=tf.Tensor(\n",
      "[[     0      0]\n",
      " [     0      1]\n",
      " [     0      2]\n",
      " ...\n",
      " [499999    197]\n",
      " [499999    198]\n",
      " [499999    199]], shape=(99999990, 2), dtype=int64), values=tf.Tensor([ 84.23115  523.32733   13.565045 ... 353.552    506.65637  591.8426  ], shape=(99999990,), dtype=float32), dense_shape=tf.Tensor([500000    200], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(\"=> Tensor Esparso:\\n\", tensor_esparso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitar o uso da memória ao tensorflow\n",
    "# podemos fazer disso uma função ao trabalhar com sistemas que serão deployados modelos baseados em redes neurais profundas e que trabalhem com GPU\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\") # obs: tensorflor só tem suporte para limitar uso de RAM em GPUs\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)] # 2048 = 2GB de RAM\n",
    "        )\n",
    "    except RuntimeError as erro:\n",
    "        print(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memória disponível: 0.25 GB\n"
     ]
    }
   ],
   "source": [
    "# verificar antes o uso\n",
    "import psutil\n",
    "\n",
    "print(f\"Memória disponível: {psutil.virtual_memory().available / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
